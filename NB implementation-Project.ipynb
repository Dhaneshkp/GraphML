{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pykNqnD3wnqA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz1Da3zLwnqG",
        "outputId": "8755b080-3e7a-451e-f1e5-a453120cc988"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.ipynb_checkpoints',\n",
              " 'Iris.csv',\n",
              " 'lNlhedMcSH63Idvr6lzE_valid.csv',\n",
              " 'NB implementation-Project.ipynb',\n",
              " 'NB implementation-Project.zip',\n",
              " 'NB implementation.ipynb',\n",
              " 'tweets.csv',\n",
              " 'word2vec_valid_data.model']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1XCoaW_wnqK",
        "outputId": "1e46f70c-ce24-431c-c3e8-7cb96d79c0ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>We started giving this to my 5 year old Labrad...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This product is easy to set up and use. I have...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>my dog has nerves and wants to itch and chew.....</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>the breeded gave us a can of Nupro when we too...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Very study, well made poop bag. Easy to open a...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15494</th>\n",
              "      <td>17348</td>\n",
              "      <td>My dog loves these!! They soft and easy to bre...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15495</th>\n",
              "      <td>17349</td>\n",
              "      <td>My 7 month old rescue pup had parvo before I a...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15496</th>\n",
              "      <td>17350</td>\n",
              "      <td>Overall I had no problem cutting my cat's nail...</td>\n",
              "      <td>cats</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15497</th>\n",
              "      <td>17351</td>\n",
              "      <td>We searched everywhere for something to keep o...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15498</th>\n",
              "      <td>17352</td>\n",
              "      <td>The biggest problem with this item is unreliab...</td>\n",
              "      <td>cats</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15499 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                               text label\n",
              "0          0  We started giving this to my 5 year old Labrad...  dogs\n",
              "1          1  This product is easy to set up and use. I have...  dogs\n",
              "2          2  my dog has nerves and wants to itch and chew.....  dogs\n",
              "3          3  the breeded gave us a can of Nupro when we too...  dogs\n",
              "4          4  Very study, well made poop bag. Easy to open a...  dogs\n",
              "...      ...                                                ...   ...\n",
              "15494  17348  My dog loves these!! They soft and easy to bre...  dogs\n",
              "15495  17349  My 7 month old rescue pup had parvo before I a...  dogs\n",
              "15496  17350  Overall I had no problem cutting my cat's nail...  cats\n",
              "15497  17351  We searched everywhere for something to keep o...  dogs\n",
              "15498  17352  The biggest problem with this item is unreliab...  cats\n",
              "\n",
              "[15499 rows x 3 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_data = pd.read_csv('lNlhedMcSH63Idvr6lzE_valid.csv')\n",
        "valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-CW9RDWwnqM"
      },
      "outputs": [],
      "source": [
        "x = valid_data['text']\n",
        "y = valid_data['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY7vSZXvwnqM"
      },
      "source": [
        "### Create train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKOlZrJMwnqP"
      },
      "outputs": [],
      "source": [
        "#create train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=56)\n",
        "x_train.index = x.index[x_train.index]\n",
        "x_test.index = x.index[x_test.index]\n",
        "y_train.index = y.index[y_train.index]\n",
        "y_test.index = y.index[y_test.index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YG2PLOEwnqU"
      },
      "source": [
        "#### some cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRlHzv8TwnqU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english') and not word.isdigit()])\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmO99hlawnqV"
      },
      "outputs": [],
      "source": [
        "x_clean=x.apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TOauw35wnqV"
      },
      "outputs": [],
      "source": [
        "x_clean_train, x_clean_test, y_train, y_test = train_test_split(x_clean, y, test_size=0.3, random_state=56)\n",
        "\n",
        "x_clean_train.index = x.index[x_clean_train.index]\n",
        "x_clean_test.index = x.index[x_clean_test.index]\n",
        "y_train.index = y.index[y_train.index]\n",
        "y_test.index = y.index[y_test.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40U8hWopwnqw"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation; a typical cleaning step\n",
        "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english') and not word.isdigit()])\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sznElx6rwnqx"
      },
      "outputs": [],
      "source": [
        "valid_data['text']=valid_data['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omr1Ro_wwnq5",
        "outputId": "66132bd0-7a65-4102-f803-e1b61d15218f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: networkx in c:\\anaconda3\\lib\\site-packages (3.1)\n",
            "Requirement already satisfied: pandas in c:\\anaconda3\\lib\\site-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in c:\\anaconda3\\lib\\site-packages (1.4.2)\n",
            "Requirement already satisfied: matplotlib in c:\\anaconda3\\lib\\site-packages (3.7.2)\n",
            "Requirement already satisfied: nltk in c:\\anaconda3\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: pykeen in c:\\anaconda3\\lib\\site-packages (1.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: click in c:\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
            "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: dataclasses-json in c:\\anaconda3\\lib\\site-packages (from pykeen) (0.5.14)\n",
            "Requirement already satisfied: click-default-group in c:\\anaconda3\\lib\\site-packages (from pykeen) (1.2.4)\n",
            "Requirement already satisfied: torch>=2.0 in c:\\anaconda3\\lib\\site-packages (from pykeen) (2.2.2)\n",
            "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from pykeen) (2.31.0)\n",
            "Requirement already satisfied: optuna>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from pykeen) (4.0.0)\n",
            "Requirement already satisfied: tabulate in c:\\anaconda3\\lib\\site-packages (from pykeen) (0.8.10)\n",
            "Requirement already satisfied: more-click in c:\\anaconda3\\lib\\site-packages (from pykeen) (0.1.2)\n",
            "Requirement already satisfied: more-itertools in c:\\anaconda3\\lib\\site-packages (from pykeen) (8.12.0)\n",
            "Requirement already satisfied: pystow>=0.4.3 in c:\\anaconda3\\lib\\site-packages (from pykeen) (0.6.1)\n",
            "Requirement already satisfied: docdata in c:\\anaconda3\\lib\\site-packages (from pykeen) (0.0.4)\n",
            "Requirement already satisfied: class-resolver>=0.5.1 in c:\\anaconda3\\lib\\site-packages (from pykeen) (0.5.4)\n",
            "Requirement already satisfied: pyyaml in c:\\anaconda3\\lib\\site-packages (from pykeen) (6.0)\n",
            "Requirement already satisfied: torch-max-mem>=0.1.1 in c:\\anaconda3\\lib\\site-packages (from pykeen) (0.1.3)\n",
            "Requirement already satisfied: torch-ppr>=0.0.7 in c:\\anaconda3\\lib\\site-packages (from pykeen) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions in c:\\anaconda3\\lib\\site-packages (from pykeen) (4.12.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\anaconda3\\lib\\site-packages (from optuna>=2.0.0->pykeen) (1.13.2)\n",
            "Requirement already satisfied: colorlog in c:\\anaconda3\\lib\\site-packages (from optuna>=2.0.0->pykeen) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\anaconda3\\lib\\site-packages (from optuna>=2.0.0->pykeen) (1.4.39)\n",
            "Requirement already satisfied: six>=1.5 in c:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from torch>=2.0->pykeen) (3.9.0)\n",
            "Requirement already satisfied: sympy in c:\\anaconda3\\lib\\site-packages (from torch>=2.0->pykeen) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from torch>=2.0->pykeen) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\anaconda3\\lib\\site-packages (from torch>=2.0->pykeen) (2024.6.1)\n",
            "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\anaconda3\\lib\\site-packages (from dataclasses-json->pykeen) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from dataclasses-json->pykeen) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests->pykeen) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->pykeen) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->pykeen) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->pykeen) (2024.8.30)\n",
            "Requirement already satisfied: Mako in c:\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna>=2.0.0->pykeen) (1.3.5)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna>=2.0.0->pykeen) (2.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->pykeen) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->pykeen) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda3\\lib\\site-packages (from sympy->torch>=2.0->pykeen) (1.3.0)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~lotly (C:\\Anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~y-cpuinfo (C:\\Anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~lotly (C:\\Anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~y-cpuinfo (C:\\Anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~lotly (C:\\Anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~y-cpuinfo (C:\\Anaconda3\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "pip install networkx pandas scikit-learn matplotlib nltk pykeen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbsHoJmCwnq6",
        "outputId": "751f1350-2f57-4a7d-8e33-9a773d37eb9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>started giving year old labrador retriever fem...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>product easy set use new puppy border collie f...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>dog nerves wants itch chewthe cone keeps frenz...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>breeded gave us nupro took scottie homehaving ...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>study well made poop bag easy open holds poop ...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15494</th>\n",
              "      <td>17348</td>\n",
              "      <td>dog loves soft easy break smaller pieces great...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15495</th>\n",
              "      <td>17349</td>\n",
              "      <td>month old rescue pup parvo adopted sensitive s...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15496</th>\n",
              "      <td>17350</td>\n",
              "      <td>overall problem cutting cats nails trimmer own...</td>\n",
              "      <td>cats</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15497</th>\n",
              "      <td>17351</td>\n",
              "      <td>searched everywhere something keep chew happy ...</td>\n",
              "      <td>dogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15498</th>\n",
              "      <td>17352</td>\n",
              "      <td>biggest problem item unreliability</td>\n",
              "      <td>cats</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15499 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                               text label\n",
              "0          0  started giving year old labrador retriever fem...  dogs\n",
              "1          1  product easy set use new puppy border collie f...  dogs\n",
              "2          2  dog nerves wants itch chewthe cone keeps frenz...  dogs\n",
              "3          3  breeded gave us nupro took scottie homehaving ...  dogs\n",
              "4          4  study well made poop bag easy open holds poop ...  dogs\n",
              "...      ...                                                ...   ...\n",
              "15494  17348  dog loves soft easy break smaller pieces great...  dogs\n",
              "15495  17349  month old rescue pup parvo adopted sensitive s...  dogs\n",
              "15496  17350  overall problem cutting cats nails trimmer own...  cats\n",
              "15497  17351  searched everywhere something keep chew happy ...  dogs\n",
              "15498  17352                 biggest problem item unreliability  cats\n",
              "\n",
              "[15499 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb7n5MRkwnq7"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from pykeen.pipeline import pipeline\n",
        "\n",
        "\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes and edges based on the data\n",
        "for index, row in valid_data.iterrows():\n",
        "    G.add_node(row['id'], label=row['label'])\n",
        "    for word in row['text'].split():\n",
        "        G.add_node(word)\n",
        "        G.add_edge(row['id'], word)\n",
        "\n",
        "# Visualize the graph\n",
        "pos = nx.spring_layout(G)\n",
        "#plt.figure(figsize=(12, 12))\n",
        "#nx.draw(G, pos, with_labels=True, node_size=50, node_color=\"skyblue\", font_size=10, font_color=\"black\")\n",
        "#plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5KlyNFpwnq7"
      },
      "outputs": [],
      "source": [
        "pip install -U pykeen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaojaEDhwnq8",
        "outputId": "3be35445-272e-4ae6-90e9-b39a60114777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0' 'contains' 'started']\n",
            "<class 'numpy.str_'> <class 'numpy.str_'> <class 'numpy.str_'>\n",
            "['0' 'contains' 'giving']\n",
            "<class 'numpy.str_'> <class 'numpy.str_'> <class 'numpy.str_'>\n",
            "['0' 'contains' 'year']\n",
            "<class 'numpy.str_'> <class 'numpy.str_'> <class 'numpy.str_'>\n",
            "['0' 'contains' 'old']\n",
            "<class 'numpy.str_'> <class 'numpy.str_'> <class 'numpy.str_'>\n",
            "['0' 'contains' 'labrador']\n",
            "<class 'numpy.str_'> <class 'numpy.str_'> <class 'numpy.str_'>\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(triples[i])\n",
        "    print(type(triples[0][0]), type(triples[0][1]), type(triples[0][2]))\n",
        "\n",
        "# Remove malformed entries\n",
        "valid_triples = [triple for triple in triples if len(triple) == 3]\n",
        "triples = np.array(valid_triples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNWakRtownq8",
        "outputId": "2752bfff-6885-4ba2-b4bf-6f8b2a07fc4c",
        "colab": {
          "referenced_widgets": [
            "d341610d12a9460fbd8830e3b6696d5d",
            "02cad2108858495b8fbbda599c959e20",
            "7117d336187144718b2972cb76af1979",
            "95f1a9e642c3440494b3384773a19f97",
            "580299a256774252a11f1120b0a3eff6",
            "01e9e5b6e40f483094903fe0d105c50a",
            "af948635131b4930b214394afc98a000",
            "8d07f4c923074e6aa36aa400e2339f09",
            "86eef5780d504c2ca795315802488bff",
            "0aaa3762f81c4216b89b8cace4ef944c",
            "a781be181c1240018158e54e118cb676",
            "8d90cee167ab41c09044f4445d47d890"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TriplesFactory(num_entities=49761, num_relations=1, create_inverse_triples=False, num_triples=555244)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No random seed is specified. Setting to 337208838.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TriplesFactory(num_entities=45531, num_relations=1, create_inverse_triples=False, num_triples=455060)\n",
            "TriplesFactory(num_entities=29063, num_relations=1, create_inverse_triples=False, num_triples=124417)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No cuda devices were available. The model runs on CPU\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d341610d12a9460fbd8830e3b6696d5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training epochs on cpu:   0%|          | 0/10 [00:00<?, ?epoch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02cad2108858495b8fbbda599c959e20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7117d336187144718b2972cb76af1979",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95f1a9e642c3440494b3384773a19f97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "580299a256774252a11f1120b0a3eff6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01e9e5b6e40f483094903fe0d105c50a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af948635131b4930b214394afc98a000",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d07f4c923074e6aa36aa400e2339f09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86eef5780d504c2ca795315802488bff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0aaa3762f81c4216b89b8cace4ef944c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a781be181c1240018158e54e118cb676",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cpu:   0%|          | 0/1778 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d90cee167ab41c09044f4445d47d890",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating on cpu:   0%|          | 0.00/124k [00:00<?, ?triple/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
            "INFO:pykeen.evaluation.evaluator:Evaluation took 8477.92s seconds\n"
          ]
        }
      ],
      "source": [
        "from pykeen.triples import TriplesFactory\n",
        "from pykeen.pipeline import pipeline\n",
        "\n",
        "triples = []\n",
        "for index, row in valid_data.iterrows():\n",
        "    for word in row['text'].split():\n",
        "        triples.append((row['id'], 'contains', word))\n",
        "valid_triples = [triple for triple in triples if len(triple) == 3]\n",
        "triples = np.array(valid_triples)\n",
        "# Convert triples to a NumPy array\n",
        "triples = np.array(triples)\n",
        "\n",
        "# Create a TriplesFactory from the labeled triples\n",
        "tf = TriplesFactory.from_labeled_triples(triples)\n",
        "\n",
        "# Print TriplesFactory details for debugging\n",
        "print(tf)\n",
        "\n",
        "train_triples, test_triples = train_test_split(triples, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create TriplesFactory objects for training and testing sets\n",
        "train_tf = TriplesFactory.from_labeled_triples(train_triples)\n",
        "test_tf = TriplesFactory.from_labeled_triples(test_triples)\n",
        "\n",
        "# Print TriplesFactory details for debugging\n",
        "print(train_tf)\n",
        "print(test_tf)\n",
        "\n",
        "# Train a KG embedding model with both training and testing triples factories\n",
        "result = pipeline(\n",
        "    training=train_tf,\n",
        "    testing=test_tf,\n",
        "    model='TransE',\n",
        "    training_kwargs=dict(num_epochs=10),\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhIrowk1wnq9"
      },
      "outputs": [],
      "source": [
        "all_entities = train_tf.entity_to_id\n",
        "embeddings = result.model.entity_representations[0](indices=torch.arange(train_tf.num_entities, device=result.model.device)).cpu().detach().numpy()\n",
        "\n",
        "# Create a DataFrame with embeddings\n",
        "embedding_df = pd.DataFrame(embeddings, index=all_entities.keys())\n",
        "\n",
        "# Merge embeddings with labels\n",
        "train_df['embedding'] = train_df.index.map(lambda x: embedding_df.loc[f'trans_{x}'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpMwtuSJwnq9",
        "outputId": "d560c0b4-f478-4cae-ccf5-d930bcf88fc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(\n",
              "  (_embeddings): Embedding(45531, 50)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUHCon62wnq-",
        "outputId": "52e3e4f6-0330-40d4-da16-0a91cff176b5"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Embedding' object has no attribute 'items'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word, embedding \u001b[38;5;129;01min\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'items'"
          ]
        }
      ],
      "source": [
        "for word, embedding in embeddings.items():\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Embedding: {embedding}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlphXXfVwnq-",
        "outputId": "19bf2169-2587-425f-80ef-78e3c99b741f"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "argument of type 'Embedding' is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[88], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings[word] \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m embeddings \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(embeddings\u001b[38;5;241m.\u001b[39mvalues()))))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert text data to embeddings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mmean([get_embedding(word, embeddings) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Prepare features and labels\u001b[39;00m\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "Cell \u001b[1;32mIn[88], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings[word] \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m embeddings \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(embeddings\u001b[38;5;241m.\u001b[39mvalues()))))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert text data to embeddings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mmean([get_embedding(word, embeddings) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Prepare features and labels\u001b[39;00m\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n",
            "Cell \u001b[1;32mIn[88], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings[word] \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m embeddings \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(embeddings\u001b[38;5;241m.\u001b[39mvalues()))))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert text data to embeddings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mmean([get_embedding(word, embeddings) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Prepare features and labels\u001b[39;00m\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n",
            "Cell \u001b[1;32mIn[88], line 2\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(word, embeddings)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(word, embeddings):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings[word] \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m embeddings \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(embeddings\u001b[38;5;241m.\u001b[39mvalues()))))\n",
            "\u001b[1;31mTypeError\u001b[0m: argument of type 'Embedding' is not iterable"
          ]
        }
      ],
      "source": [
        "def get_embedding(word, embeddings):\n",
        "    return embeddings[word] if word in embeddings else np.zeros(len(next(iter(embeddings.values()))))\n",
        "\n",
        "# Convert text data to embeddings\n",
        "valid_data['embedding'] = valid_data['text'].apply(lambda x: np.mean([get_embedding(word, embeddings) for word in x.split()], axis=0))\n",
        "\n",
        "# Prepare features and labels\n",
        "X = np.vstack(valid_data['embedding'].values)\n",
        "y = valid_data['label']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDqq9SoKwnq_",
        "outputId": "08930f81-5f54-48e5-9d72-f0e66dabd909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TriplesFactory(num_entities=49761, num_relations=1, create_inverse_triples=False, num_triples=555244)\n",
            "Model: TransE\n",
            "Training kwargs: {'num_epochs': 100}\n"
          ]
        }
      ],
      "source": [
        "print(tf)\n",
        "print('Model:', 'TransE')\n",
        "print('Training kwargs:', dict(num_epochs=100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhQ0jpOgwnq_"
      },
      "outputs": [],
      "source": [
        "x = list(data['embedding'])\n",
        "y = data['label']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=56)\n",
        "\n",
        "# Convert list of arrays to 2D array\n",
        "x_train = np.array(x_train.tolist())\n",
        "x_test = np.array(x_test.tolist())\n",
        "\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(x_train, y_train)\n",
        "predictions = naive_bayes.predict(x_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print(classification_report(y_test, predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Nd9dWstwnrA"
      },
      "outputs": [],
      "source": [
        "Premium_Lookup_Table_JL.fac"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}