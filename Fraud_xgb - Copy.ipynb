{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10328793,"sourceType":"datasetVersion","datasetId":6395417},{"sourceId":10467187,"sourceType":"datasetVersion","datasetId":6480710}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Dhaneshkp/GraphML/blob/main/Fraud_xgb%20-%20Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:18.032434Z","iopub.execute_input":"2025-01-14T16:04:18.032626Z","iopub.status.idle":"2025-01-14T16:04:19.019290Z","shell.execute_reply.started":"2025-01-14T16:04:18.032607Z","shell.execute_reply":"2025-01-14T16:04:19.018655Z"},"id":"6e127a6c","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"!pip install --upgrade certifi\n\n!pip install --trusted-host files.pythonhosted.org optuna\n\n","metadata":{"id":"cca9ea61"}},{"cell_type":"code","source":"#os.listdir(\"/kaggle/input/fraud-detection\")","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:19.020043Z","iopub.execute_input":"2025-01-14T16:04:19.020459Z","iopub.status.idle":"2025-01-14T16:04:19.024001Z","shell.execute_reply.started":"2025-01-14T16:04:19.020426Z","shell.execute_reply":"2025-01-14T16:04:19.023158Z"},"id":"2ae5c024","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/fraud-detection/fraudTrain.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:19.025466Z","iopub.execute_input":"2025-01-14T16:04:19.025689Z","iopub.status.idle":"2025-01-14T16:04:28.069401Z","shell.execute_reply.started":"2025-01-14T16:04:19.025671Z","shell.execute_reply":"2025-01-14T16:04:28.068704Z"},"id":"13e8ce13","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\ndef are_cc_numbers_unique(df, cc_column):\n\n    try:\n      # Check if the specified column exists in the DataFrame.\n      if cc_column not in df.columns:\n          print(f\"Error: Column '{cc_column}' not found in the DataFrame.\")\n          return False\n\n      return df[cc_column].nunique() == len(df)\n\n    except Exception as e:\n      print(f\"An error occurred: {e}\")\n      return False\n\n\nare_unique = are_cc_numbers_unique(data, 'cc_num')\n\nif are_unique:\n     print(\"All credit card numbers are unique.\")\nelse:\n     print(\"Some credit card numbers are duplicated.\")","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:28.070536Z","iopub.execute_input":"2025-01-14T16:04:28.070772Z","iopub.status.idle":"2025-01-14T16:04:28.090717Z","shell.execute_reply.started":"2025-01-14T16:04:28.070752Z","shell.execute_reply":"2025-01-14T16:04:28.089886Z"},"id":"EeWV_J0t74Us","outputId":"93fd8b16-ea09-4ab6-de77-503548d7b940","trusted":true},"outputs":[{"name":"stdout","text":"Some credit card numbers are duplicated.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\nimport datetime\n\ndata['trans_date_trans_time'] = pd.to_datetime(data['trans_date_trans_time'])\n\n# Extract the time of day as an integer representing minutes since midnight\ndata['time_of_day'] = (data['trans_date_trans_time'].dt.hour * 60) + data['trans_date_trans_time'].dt.minute\n\n\ndata['time_of_day_category'] = pd.cut(data['time_of_day'], bins=[0, 6*60, 12*60, 18*60, 24*60],\n                                      labels=['Night', 'Morning', 'Afternoon', 'Evening'], right=False)\n\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:28.091616Z","iopub.execute_input":"2025-01-14T16:04:28.091896Z","iopub.status.idle":"2025-01-14T16:04:28.542282Z","shell.execute_reply.started":"2025-01-14T16:04:28.091864Z","shell.execute_reply":"2025-01-14T16:04:28.541548Z"},"id":"po4tbvvL2mBu","outputId":"e1e289d0-7827-4ec1-f939-e7b16400da17","trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0 trans_date_trans_time            cc_num  \\\n0           0   2019-01-01 00:00:18  2703186189652095   \n1           1   2019-01-01 00:00:44      630423337322   \n2           2   2019-01-01 00:00:51    38859492057661   \n3           3   2019-01-01 00:01:16  3534093764340240   \n4           4   2019-01-01 00:03:06   375534208663984   \n\n                             merchant       category     amt      first  \\\n0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n\n      last gender                        street  ... city_pop  \\\n0    Banks      F                561 Perry Cove  ...     3495   \n1     Gill      F  43039 Riley Greens Suite 393  ...      149   \n2  Sanchez      M      594 White Dale Suite 530  ...     4154   \n3    White      M   9443 Cynthia Court Apt. 038  ...     1939   \n4   Garcia      M              408 Bradley Rest  ...       99   \n\n                                 job         dob  \\\n0          Psychologist, counselling  1988-03-09   \n1  Special educational needs teacher  1978-06-21   \n2        Nature conservation officer  1962-01-19   \n3                    Patent attorney  1967-01-12   \n4     Dance movement psychotherapist  1986-03-28   \n\n                          trans_num   unix_time  merch_lat  merch_long  \\\n0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n\n  is_fraud time_of_day  time_of_day_category  \n0        0           0                 Night  \n1        0           0                 Night  \n2        0           0                 Night  \n3        0           1                 Night  \n4        0           3                 Night  \n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>trans_date_trans_time</th>\n      <th>cc_num</th>\n      <th>merchant</th>\n      <th>category</th>\n      <th>amt</th>\n      <th>first</th>\n      <th>last</th>\n      <th>gender</th>\n      <th>street</th>\n      <th>...</th>\n      <th>city_pop</th>\n      <th>job</th>\n      <th>dob</th>\n      <th>trans_num</th>\n      <th>unix_time</th>\n      <th>merch_lat</th>\n      <th>merch_long</th>\n      <th>is_fraud</th>\n      <th>time_of_day</th>\n      <th>time_of_day_category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2019-01-01 00:00:18</td>\n      <td>2703186189652095</td>\n      <td>fraud_Rippin, Kub and Mann</td>\n      <td>misc_net</td>\n      <td>4.97</td>\n      <td>Jennifer</td>\n      <td>Banks</td>\n      <td>F</td>\n      <td>561 Perry Cove</td>\n      <td>...</td>\n      <td>3495</td>\n      <td>Psychologist, counselling</td>\n      <td>1988-03-09</td>\n      <td>0b242abb623afc578575680df30655b9</td>\n      <td>1325376018</td>\n      <td>36.011293</td>\n      <td>-82.048315</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2019-01-01 00:00:44</td>\n      <td>630423337322</td>\n      <td>fraud_Heller, Gutmann and Zieme</td>\n      <td>grocery_pos</td>\n      <td>107.23</td>\n      <td>Stephanie</td>\n      <td>Gill</td>\n      <td>F</td>\n      <td>43039 Riley Greens Suite 393</td>\n      <td>...</td>\n      <td>149</td>\n      <td>Special educational needs teacher</td>\n      <td>1978-06-21</td>\n      <td>1f76529f8574734946361c461b024d99</td>\n      <td>1325376044</td>\n      <td>49.159047</td>\n      <td>-118.186462</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2019-01-01 00:00:51</td>\n      <td>38859492057661</td>\n      <td>fraud_Lind-Buckridge</td>\n      <td>entertainment</td>\n      <td>220.11</td>\n      <td>Edward</td>\n      <td>Sanchez</td>\n      <td>M</td>\n      <td>594 White Dale Suite 530</td>\n      <td>...</td>\n      <td>4154</td>\n      <td>Nature conservation officer</td>\n      <td>1962-01-19</td>\n      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n      <td>1325376051</td>\n      <td>43.150704</td>\n      <td>-112.154481</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2019-01-01 00:01:16</td>\n      <td>3534093764340240</td>\n      <td>fraud_Kutch, Hermiston and Farrell</td>\n      <td>gas_transport</td>\n      <td>45.00</td>\n      <td>Jeremy</td>\n      <td>White</td>\n      <td>M</td>\n      <td>9443 Cynthia Court Apt. 038</td>\n      <td>...</td>\n      <td>1939</td>\n      <td>Patent attorney</td>\n      <td>1967-01-12</td>\n      <td>6b849c168bdad6f867558c3793159a81</td>\n      <td>1325376076</td>\n      <td>47.034331</td>\n      <td>-112.561071</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2019-01-01 00:03:06</td>\n      <td>375534208663984</td>\n      <td>fraud_Keeling-Crist</td>\n      <td>misc_pos</td>\n      <td>41.96</td>\n      <td>Tyler</td>\n      <td>Garcia</td>\n      <td>M</td>\n      <td>408 Bradley Rest</td>\n      <td>...</td>\n      <td>99</td>\n      <td>Dance movement psychotherapist</td>\n      <td>1986-03-28</td>\n      <td>a41d7549acf90789359a9aa5346dcb46</td>\n      <td>1325376186</td>\n      <td>38.674999</td>\n      <td>-78.632459</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Night</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"\ndata['unix_time_c'] = pd.to_datetime(data['unix_time'], unit='s')\n\n# Extract the time of day as an integer representing minutes since midnight\ndata['time_of_day_uc'] = (data['unix_time_c'].dt.hour * 60) + data['unix_time_c'].dt.minute\n\ndata['time_of_day_category_uc'] = pd.cut(data['time_of_day_uc'], bins=[0, 6*60, 12*60, 18*60, 24*60],\n                                      labels=['Night', 'Morning', 'Afternoon', 'Evening'], right=False)\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:28.543083Z","iopub.execute_input":"2025-01-14T16:04:28.543321Z","iopub.status.idle":"2025-01-14T16:04:28.712107Z","shell.execute_reply.started":"2025-01-14T16:04:28.543298Z","shell.execute_reply":"2025-01-14T16:04:28.711257Z"},"id":"Vx2fexCW7GDg","outputId":"5d34760d-d3bb-40ee-cbad-3df621c0c3bb","trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0 trans_date_trans_time            cc_num  \\\n0           0   2019-01-01 00:00:18  2703186189652095   \n1           1   2019-01-01 00:00:44      630423337322   \n2           2   2019-01-01 00:00:51    38859492057661   \n3           3   2019-01-01 00:01:16  3534093764340240   \n4           4   2019-01-01 00:03:06   375534208663984   \n\n                             merchant       category     amt      first  \\\n0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n\n      last gender                        street  ...  \\\n0    Banks      F                561 Perry Cove  ...   \n1     Gill      F  43039 Riley Greens Suite 393  ...   \n2  Sanchez      M      594 White Dale Suite 530  ...   \n3    White      M   9443 Cynthia Court Apt. 038  ...   \n4   Garcia      M              408 Bradley Rest  ...   \n\n                          trans_num   unix_time  merch_lat  merch_long  \\\n0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n\n   is_fraud  time_of_day time_of_day_category         unix_time_c  \\\n0         0            0                Night 2012-01-01 00:00:18   \n1         0            0                Night 2012-01-01 00:00:44   \n2         0            0                Night 2012-01-01 00:00:51   \n3         0            1                Night 2012-01-01 00:01:16   \n4         0            3                Night 2012-01-01 00:03:06   \n\n  time_of_day_uc  time_of_day_category_uc  \n0              0                    Night  \n1              0                    Night  \n2              0                    Night  \n3              1                    Night  \n4              3                    Night  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>trans_date_trans_time</th>\n      <th>cc_num</th>\n      <th>merchant</th>\n      <th>category</th>\n      <th>amt</th>\n      <th>first</th>\n      <th>last</th>\n      <th>gender</th>\n      <th>street</th>\n      <th>...</th>\n      <th>trans_num</th>\n      <th>unix_time</th>\n      <th>merch_lat</th>\n      <th>merch_long</th>\n      <th>is_fraud</th>\n      <th>time_of_day</th>\n      <th>time_of_day_category</th>\n      <th>unix_time_c</th>\n      <th>time_of_day_uc</th>\n      <th>time_of_day_category_uc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2019-01-01 00:00:18</td>\n      <td>2703186189652095</td>\n      <td>fraud_Rippin, Kub and Mann</td>\n      <td>misc_net</td>\n      <td>4.97</td>\n      <td>Jennifer</td>\n      <td>Banks</td>\n      <td>F</td>\n      <td>561 Perry Cove</td>\n      <td>...</td>\n      <td>0b242abb623afc578575680df30655b9</td>\n      <td>1325376018</td>\n      <td>36.011293</td>\n      <td>-82.048315</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Night</td>\n      <td>2012-01-01 00:00:18</td>\n      <td>0</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2019-01-01 00:00:44</td>\n      <td>630423337322</td>\n      <td>fraud_Heller, Gutmann and Zieme</td>\n      <td>grocery_pos</td>\n      <td>107.23</td>\n      <td>Stephanie</td>\n      <td>Gill</td>\n      <td>F</td>\n      <td>43039 Riley Greens Suite 393</td>\n      <td>...</td>\n      <td>1f76529f8574734946361c461b024d99</td>\n      <td>1325376044</td>\n      <td>49.159047</td>\n      <td>-118.186462</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Night</td>\n      <td>2012-01-01 00:00:44</td>\n      <td>0</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2019-01-01 00:00:51</td>\n      <td>38859492057661</td>\n      <td>fraud_Lind-Buckridge</td>\n      <td>entertainment</td>\n      <td>220.11</td>\n      <td>Edward</td>\n      <td>Sanchez</td>\n      <td>M</td>\n      <td>594 White Dale Suite 530</td>\n      <td>...</td>\n      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n      <td>1325376051</td>\n      <td>43.150704</td>\n      <td>-112.154481</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Night</td>\n      <td>2012-01-01 00:00:51</td>\n      <td>0</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2019-01-01 00:01:16</td>\n      <td>3534093764340240</td>\n      <td>fraud_Kutch, Hermiston and Farrell</td>\n      <td>gas_transport</td>\n      <td>45.00</td>\n      <td>Jeremy</td>\n      <td>White</td>\n      <td>M</td>\n      <td>9443 Cynthia Court Apt. 038</td>\n      <td>...</td>\n      <td>6b849c168bdad6f867558c3793159a81</td>\n      <td>1325376076</td>\n      <td>47.034331</td>\n      <td>-112.561071</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Night</td>\n      <td>2012-01-01 00:01:16</td>\n      <td>1</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2019-01-01 00:03:06</td>\n      <td>375534208663984</td>\n      <td>fraud_Keeling-Crist</td>\n      <td>misc_pos</td>\n      <td>41.96</td>\n      <td>Tyler</td>\n      <td>Garcia</td>\n      <td>M</td>\n      <td>408 Bradley Rest</td>\n      <td>...</td>\n      <td>a41d7549acf90789359a9aa5346dcb46</td>\n      <td>1325376186</td>\n      <td>38.674999</td>\n      <td>-78.632459</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Night</td>\n      <td>2012-01-01 00:03:06</td>\n      <td>3</td>\n      <td>Night</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:28.713001Z","iopub.execute_input":"2025-01-14T16:04:28.713327Z","iopub.status.idle":"2025-01-14T16:04:28.718391Z","shell.execute_reply.started":"2025-01-14T16:04:28.713303Z","shell.execute_reply":"2025-01-14T16:04:28.717531Z"},"id":"ad7c98b3","outputId":"9a60a7c3-0045-444d-a920-f7153a94a875","scrolled":true,"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n       'merch_lat', 'merch_long', 'is_fraud', 'time_of_day',\n       'time_of_day_category', 'unix_time_c', 'time_of_day_uc',\n       'time_of_day_category_uc'],\n      dtype='object')"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:28.720934Z","iopub.execute_input":"2025-01-14T16:04:28.721153Z","iopub.status.idle":"2025-01-14T16:04:29.347405Z","shell.execute_reply.started":"2025-01-14T16:04:28.721135Z","shell.execute_reply":"2025-01-14T16:04:29.346525Z"},"id":"c6f27470","outputId":"dc7c595f-79cd-43d8-842f-ef479b8f436a","trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"         Unnamed: 0          trans_date_trans_time        cc_num  \\\ncount  1.296675e+06                        1296675  1.296675e+06   \nmean   6.483370e+05  2019-10-03 12:47:28.070214144  4.171920e+17   \nmin    0.000000e+00            2019-01-01 00:00:18  6.041621e+10   \n25%    3.241685e+05     2019-06-03 19:12:22.500000  1.800429e+14   \n50%    6.483370e+05            2019-10-03 07:35:47  3.521417e+15   \n75%    9.725055e+05     2020-01-28 15:02:55.500000  4.642255e+15   \nmax    1.296674e+06            2020-06-21 12:13:37  4.992346e+18   \nstd    3.743180e+05                            NaN  1.308806e+18   \n\n                amt           zip           lat          long      city_pop  \\\ncount  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \nmean   7.035104e+01  4.880067e+04  3.853762e+01 -9.022634e+01  8.882444e+04   \nmin    1.000000e+00  1.257000e+03  2.002710e+01 -1.656723e+02  2.300000e+01   \n25%    9.650000e+00  2.623700e+04  3.462050e+01 -9.679800e+01  7.430000e+02   \n50%    4.752000e+01  4.817400e+04  3.935430e+01 -8.747690e+01  2.456000e+03   \n75%    8.314000e+01  7.204200e+04  4.194040e+01 -8.015800e+01  2.032800e+04   \nmax    2.894890e+04  9.978300e+04  6.669330e+01 -6.795030e+01  2.906700e+06   \nstd    1.603160e+02  2.689322e+04  5.075808e+00  1.375908e+01  3.019564e+05   \n\n          unix_time     merch_lat    merch_long      is_fraud   time_of_day  \\\ncount  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \nmean   1.349244e+09  3.853734e+01 -9.022646e+01  5.788652e-03  7.977868e+02   \nmin    1.325376e+09  1.902779e+01 -1.666712e+02  0.000000e+00  0.000000e+00   \n25%    1.338751e+09  3.473357e+01 -9.689728e+01  0.000000e+00  4.580000e+02   \n50%    1.349250e+09  3.936568e+01 -8.743839e+01  0.000000e+00  8.480000e+02   \n75%    1.359385e+09  4.195716e+01 -8.023680e+01  0.000000e+00  1.145000e+03   \nmax    1.371817e+09  6.751027e+01 -6.695090e+01  1.000000e+00  1.439000e+03   \nstd    1.284128e+07  5.109788e+00  1.377109e+01  7.586269e-02  4.094252e+02   \n\n                         unix_time_c  time_of_day_uc  \ncount                        1296675    1.296675e+06  \nmean   2012-10-03 05:53:56.726123008    7.977868e+02  \nmin              2012-01-01 00:00:18    0.000000e+00  \n25%       2012-06-03 19:12:22.500000    4.580000e+02  \n50%              2012-10-03 07:35:47    8.480000e+02  \n75%       2013-01-28 15:02:55.500000    1.145000e+03  \nmax              2013-06-21 12:13:37    1.439000e+03  \nstd                              NaN    4.094252e+02  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>trans_date_trans_time</th>\n      <th>cc_num</th>\n      <th>amt</th>\n      <th>zip</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>city_pop</th>\n      <th>unix_time</th>\n      <th>merch_lat</th>\n      <th>merch_long</th>\n      <th>is_fraud</th>\n      <th>time_of_day</th>\n      <th>unix_time_c</th>\n      <th>time_of_day_uc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.296675e+06</td>\n      <td>1296675</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1.296675e+06</td>\n      <td>1296675</td>\n      <td>1.296675e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6.483370e+05</td>\n      <td>2019-10-03 12:47:28.070214144</td>\n      <td>4.171920e+17</td>\n      <td>7.035104e+01</td>\n      <td>4.880067e+04</td>\n      <td>3.853762e+01</td>\n      <td>-9.022634e+01</td>\n      <td>8.882444e+04</td>\n      <td>1.349244e+09</td>\n      <td>3.853734e+01</td>\n      <td>-9.022646e+01</td>\n      <td>5.788652e-03</td>\n      <td>7.977868e+02</td>\n      <td>2012-10-03 05:53:56.726123008</td>\n      <td>7.977868e+02</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>2019-01-01 00:00:18</td>\n      <td>6.041621e+10</td>\n      <td>1.000000e+00</td>\n      <td>1.257000e+03</td>\n      <td>2.002710e+01</td>\n      <td>-1.656723e+02</td>\n      <td>2.300000e+01</td>\n      <td>1.325376e+09</td>\n      <td>1.902779e+01</td>\n      <td>-1.666712e+02</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>2012-01-01 00:00:18</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.241685e+05</td>\n      <td>2019-06-03 19:12:22.500000</td>\n      <td>1.800429e+14</td>\n      <td>9.650000e+00</td>\n      <td>2.623700e+04</td>\n      <td>3.462050e+01</td>\n      <td>-9.679800e+01</td>\n      <td>7.430000e+02</td>\n      <td>1.338751e+09</td>\n      <td>3.473357e+01</td>\n      <td>-9.689728e+01</td>\n      <td>0.000000e+00</td>\n      <td>4.580000e+02</td>\n      <td>2012-06-03 19:12:22.500000</td>\n      <td>4.580000e+02</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6.483370e+05</td>\n      <td>2019-10-03 07:35:47</td>\n      <td>3.521417e+15</td>\n      <td>4.752000e+01</td>\n      <td>4.817400e+04</td>\n      <td>3.935430e+01</td>\n      <td>-8.747690e+01</td>\n      <td>2.456000e+03</td>\n      <td>1.349250e+09</td>\n      <td>3.936568e+01</td>\n      <td>-8.743839e+01</td>\n      <td>0.000000e+00</td>\n      <td>8.480000e+02</td>\n      <td>2012-10-03 07:35:47</td>\n      <td>8.480000e+02</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9.725055e+05</td>\n      <td>2020-01-28 15:02:55.500000</td>\n      <td>4.642255e+15</td>\n      <td>8.314000e+01</td>\n      <td>7.204200e+04</td>\n      <td>4.194040e+01</td>\n      <td>-8.015800e+01</td>\n      <td>2.032800e+04</td>\n      <td>1.359385e+09</td>\n      <td>4.195716e+01</td>\n      <td>-8.023680e+01</td>\n      <td>0.000000e+00</td>\n      <td>1.145000e+03</td>\n      <td>2013-01-28 15:02:55.500000</td>\n      <td>1.145000e+03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.296674e+06</td>\n      <td>2020-06-21 12:13:37</td>\n      <td>4.992346e+18</td>\n      <td>2.894890e+04</td>\n      <td>9.978300e+04</td>\n      <td>6.669330e+01</td>\n      <td>-6.795030e+01</td>\n      <td>2.906700e+06</td>\n      <td>1.371817e+09</td>\n      <td>6.751027e+01</td>\n      <td>-6.695090e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.439000e+03</td>\n      <td>2013-06-21 12:13:37</td>\n      <td>1.439000e+03</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.743180e+05</td>\n      <td>NaN</td>\n      <td>1.308806e+18</td>\n      <td>1.603160e+02</td>\n      <td>2.689322e+04</td>\n      <td>5.075808e+00</td>\n      <td>1.375908e+01</td>\n      <td>3.019564e+05</td>\n      <td>1.284128e+07</td>\n      <td>5.109788e+00</td>\n      <td>1.377109e+01</td>\n      <td>7.586269e-02</td>\n      <td>4.094252e+02</td>\n      <td>NaN</td>\n      <td>4.094252e+02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"data.describe(include='object')","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:29.349271Z","iopub.execute_input":"2025-01-14T16:04:29.349504Z","iopub.status.idle":"2025-01-14T16:04:31.859294Z","shell.execute_reply.started":"2025-01-14T16:04:29.349486Z","shell.execute_reply":"2025-01-14T16:04:31.858482Z"},"id":"ec94315d","outputId":"2bbb9627-cd12-4894-e417-6144ead6b4a1","trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                 merchant       category        first     last   gender  \\\ncount             1296675        1296675      1296675  1296675  1296675   \nunique                693             14          352      481        2   \ntop     fraud_Kilback LLC  gas_transport  Christopher    Smith        F   \nfreq                 4403         131659        26669    28794   709863   \n\n                     street        city    state                job  \\\ncount               1296675     1296675  1296675            1296675   \nunique                  983         894       51                494   \ntop     864 Reynolds Plains  Birmingham       TX  Film/video editor   \nfreq                   3123        5617    94876               9779   \n\n               dob                         trans_num  \ncount      1296675                           1296675  \nunique         968                           1296675  \ntop     1977-03-23  8f7c8e4ab7f25875d753b422917c98c9  \nfreq          5636                                 1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merchant</th>\n      <th>category</th>\n      <th>first</th>\n      <th>last</th>\n      <th>gender</th>\n      <th>street</th>\n      <th>city</th>\n      <th>state</th>\n      <th>job</th>\n      <th>dob</th>\n      <th>trans_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1296675</td>\n      <td>1296675</td>\n      <td>1296675</td>\n      <td>1296675</td>\n      <td>1296675</td>\n      <td>1296675</td>\n      <td>1296675</td>\n      <td>1296675</td>\n      <td>1296675</td>\n      <td>1296675</td>\n      <td>1296675</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>693</td>\n      <td>14</td>\n      <td>352</td>\n      <td>481</td>\n      <td>2</td>\n      <td>983</td>\n      <td>894</td>\n      <td>51</td>\n      <td>494</td>\n      <td>968</td>\n      <td>1296675</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>fraud_Kilback LLC</td>\n      <td>gas_transport</td>\n      <td>Christopher</td>\n      <td>Smith</td>\n      <td>F</td>\n      <td>864 Reynolds Plains</td>\n      <td>Birmingham</td>\n      <td>TX</td>\n      <td>Film/video editor</td>\n      <td>1977-03-23</td>\n      <td>8f7c8e4ab7f25875d753b422917c98c9</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>4403</td>\n      <td>131659</td>\n      <td>26669</td>\n      <td>28794</td>\n      <td>709863</td>\n      <td>3123</td>\n      <td>5617</td>\n      <td>94876</td>\n      <td>9779</td>\n      <td>5636</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"train_df = data.drop(['Unnamed: 0', 'trans_date_trans_time','trans_num', 'unix_time'],axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:31.860075Z","iopub.execute_input":"2025-01-14T16:04:31.860357Z","iopub.status.idle":"2025-01-14T16:04:32.021141Z","shell.execute_reply.started":"2025-01-14T16:04:31.860336Z","shell.execute_reply":"2025-01-14T16:04:32.020202Z"},"id":"002450e0","trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_df=train_df.sample(frac=0.5,random_state=1)# if the data us indded by a person or a cc num then this sampling isnt appropriate","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:32.022042Z","iopub.execute_input":"2025-01-14T16:04:32.022307Z","iopub.status.idle":"2025-01-14T16:04:32.531862Z","shell.execute_reply.started":"2025-01-14T16:04:32.022286Z","shell.execute_reply":"2025-01-14T16:04:32.530935Z"},"id":"3f8Lm9DqqzSK","trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"id":"v84qETkr9Zlt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['distance']= (train_df['lat'] - train_df['merch_lat'])**2 + (train_df['long'] - train_df['merch_long'])**2","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:32.532750Z","iopub.execute_input":"2025-01-14T16:04:32.532986Z","iopub.status.idle":"2025-01-14T16:04:32.543886Z","shell.execute_reply.started":"2025-01-14T16:04:32.532966Z","shell.execute_reply":"2025-01-14T16:04:32.543010Z"},"id":"d3bfb74c","trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    text = ' '.join([word for word in text.split() if word not in stopwords.words('english') and not word.isdigit()])\n    return text\n\n# Apply cleaning to relevant columns\n#train_df['merchant'] = train_df['merchant'].apply(clean_text)\n#train_df['category'] = train_df['category'].apply(clean_text)\ntrain_df['city_state'] = train_df['city'] + '_' + train_df['state']","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:32.544755Z","iopub.execute_input":"2025-01-14T16:04:32.545197Z","iopub.status.idle":"2025-01-14T16:04:33.381888Z","shell.execute_reply.started":"2025-01-14T16:04:32.545151Z","shell.execute_reply":"2025-01-14T16:04:33.381036Z"},"id":"6c1a21da","outputId":"939ea352-896d-4389-833f-6557a03d9b92","trusted":true},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"train_df['city_state'] = train_df['city'] + '_' + train_df['state']","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:33.382725Z","iopub.execute_input":"2025-01-14T16:04:33.383035Z","iopub.status.idle":"2025-01-14T16:04:33.543145Z","shell.execute_reply.started":"2025-01-14T16:04:33.383002Z","shell.execute_reply":"2025-01-14T16:04:33.542500Z"},"id":"737d7dfa","trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from datetime import datetime\n\n# Function to calculate age\ndef calculate_age(dob):\n    dob = str(dob)\n    today = datetime.today()\n    dob = datetime.strptime(dob, '%Y-%m-%d')\n    age = today.year - dob.year - ((today.month, today.day) < (dob.month, dob.day))\n    return age\n\n# Apply the function to the 'dob' column\ntrain_df['age'] = data['dob'].apply(calculate_age)\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:33.543743Z","iopub.execute_input":"2025-01-14T16:04:33.544066Z","iopub.status.idle":"2025-01-14T16:04:43.365947Z","shell.execute_reply.started":"2025-01-14T16:04:33.544045Z","shell.execute_reply":"2025-01-14T16:04:43.365279Z"},"id":"152bbec2","trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#train_df = train_df.dropna(subset=['dob'])","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.366718Z","iopub.execute_input":"2025-01-14T16:04:43.367002Z","iopub.status.idle":"2025-01-14T16:04:43.370356Z","shell.execute_reply.started":"2025-01-14T16:04:43.366969Z","shell.execute_reply":"2025-01-14T16:04:43.369603Z"},"id":"dReaIvq3ApvO","trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"categorical_columns = ['category', 'gender', 'job','city','state','merchant','street','city_state']\nfor column in categorical_columns:\n    train_df[column] = train_df[column].astype('category')","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.371113Z","iopub.execute_input":"2025-01-14T16:04:43.371361Z","iopub.status.idle":"2025-01-14T16:04:43.763888Z","shell.execute_reply.started":"2025-01-14T16:04:43.371342Z","shell.execute_reply":"2025-01-14T16:04:43.763157Z"},"id":"dafbcc9e","trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.764633Z","iopub.execute_input":"2025-01-14T16:04:43.764857Z","iopub.status.idle":"2025-01-14T16:04:43.771026Z","shell.execute_reply.started":"2025-01-14T16:04:43.764838Z","shell.execute_reply":"2025-01-14T16:04:43.770160Z"},"id":"8e08f7ab","outputId":"a833874d-a63e-48b6-d74e-e272b53c84db","trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"cc_num                              int64\nmerchant                         category\ncategory                         category\namt                               float64\nfirst                              object\nlast                               object\ngender                           category\nstreet                           category\ncity                             category\nstate                            category\nzip                                 int64\nlat                               float64\nlong                              float64\ncity_pop                            int64\njob                              category\ndob                                object\nmerch_lat                         float64\nmerch_long                        float64\nis_fraud                            int64\ntime_of_day                         int64\ntime_of_day_category             category\nunix_time_c                datetime64[ns]\ntime_of_day_uc                      int64\ntime_of_day_category_uc          category\ndistance                          float64\ncity_state                       category\nage                                 int64\ndtype: object"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"train_df.drop(['merch_lat', 'merch_long','lat', 'long'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.771856Z","iopub.execute_input":"2025-01-14T16:04:43.772152Z","iopub.status.idle":"2025-01-14T16:04:43.849732Z","shell.execute_reply.started":"2025-01-14T16:04:43.772124Z","shell.execute_reply":"2025-01-14T16:04:43.849033Z"},"id":"b973f56e","trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.850521Z","iopub.execute_input":"2025-01-14T16:04:43.850723Z","iopub.status.idle":"2025-01-14T16:04:43.855733Z","shell.execute_reply.started":"2025-01-14T16:04:43.850706Z","shell.execute_reply":"2025-01-14T16:04:43.854939Z"},"id":"e85e852e","outputId":"05142913-afab-4953-a639-31e3048328c4","trusted":true},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Index(['cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender',\n       'street', 'city', 'state', 'zip', 'city_pop', 'job', 'dob', 'is_fraud',\n       'time_of_day', 'time_of_day_category', 'unix_time_c', 'time_of_day_uc',\n       'time_of_day_category_uc', 'distance', 'city_state', 'age'],\n      dtype='object')"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"train_df.drop(['street','zip','city_pop'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.856547Z","iopub.execute_input":"2025-01-14T16:04:43.856843Z","iopub.status.idle":"2025-01-14T16:04:43.914735Z","shell.execute_reply.started":"2025-01-14T16:04:43.856813Z","shell.execute_reply":"2025-01-14T16:04:43.914037Z"},"id":"fff694bf","trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"#train_df.drop(['dob'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.915577Z","iopub.execute_input":"2025-01-14T16:04:43.915817Z","iopub.status.idle":"2025-01-14T16:04:43.919058Z","shell.execute_reply.started":"2025-01-14T16:04:43.915794Z","shell.execute_reply":"2025-01-14T16:04:43.918250Z"},"id":"210cafd8","trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"#train_df.to_csv(\"train_df_new.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.923564Z","iopub.execute_input":"2025-01-14T16:04:43.923809Z","iopub.status.idle":"2025-01-14T16:04:43.933818Z","shell.execute_reply.started":"2025-01-14T16:04:43.923788Z","shell.execute_reply":"2025-01-14T16:04:43.933090Z"},"id":"9af53317","trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"#train_df=pd.read_csv(\"train_df_new.csv\")\n#train_df.drop('Unnamed: 0',axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.935386Z","iopub.execute_input":"2025-01-14T16:04:43.935612Z","iopub.status.idle":"2025-01-14T16:04:43.947273Z","shell.execute_reply.started":"2025-01-14T16:04:43.935593Z","shell.execute_reply":"2025-01-14T16:04:43.946611Z"},"id":"ea8779c3","scrolled":true,"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"!pip install pykeen","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:43.948131Z","iopub.execute_input":"2025-01-14T16:04:43.948432Z","iopub.status.idle":"2025-01-14T16:04:50.352549Z","shell.execute_reply.started":"2025-01-14T16:04:43.948396Z","shell.execute_reply":"2025-01-14T16:04:50.351489Z"},"id":"iebAgA3ULoud","outputId":"790e66d1-4958-449a-fb67-b7558cc725e9","trusted":true},"outputs":[{"name":"stdout","text":"Collecting pykeen\n  Downloading pykeen-1.11.0-py3-none-any.whl.metadata (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.6.7)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pykeen) (1.26.4)\nRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pykeen) (1.13.1)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from pykeen) (8.1.7)\nCollecting click-default-group (from pykeen)\n  Downloading click_default_group-1.2.4-py2.py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pykeen) (1.2.2)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from pykeen) (2.4.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pykeen) (4.66.5)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pykeen) (2.32.3)\nRequirement already satisfied: optuna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pykeen) (4.1.0)\nRequirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pykeen) (2.1.4)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.9.0)\nCollecting more-click (from pykeen)\n  Downloading more_click-0.1.2-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from pykeen) (10.5.0)\nCollecting pystow>=0.4.3 (from pykeen)\n  Downloading pystow-0.6.1-py3-none-any.whl.metadata (17 kB)\nCollecting docdata (from pykeen)\n  Downloading docdata-0.0.4-py3-none-any.whl.metadata (13 kB)\nCollecting class-resolver>=0.5.1 (from pykeen)\n  Downloading class_resolver-0.5.4-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pykeen) (6.0.2)\nCollecting torch-max-mem>=0.1.1 (from pykeen)\n  Downloading torch_max_mem-0.1.3-py3-none-any.whl.metadata (7.4 kB)\nCollecting torch-ppr>=0.0.7 (from pykeen)\n  Downloading torch_ppr-0.0.8-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pykeen) (4.12.2)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (1.14.0)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (6.9.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (24.1)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (2.0.35)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->pykeen) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->pykeen) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->pykeen) (2024.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (3.16.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (2024.6.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->pykeen) (3.23.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->pykeen) (0.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (2024.8.30)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pykeen) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pykeen) (3.5.0)\nRequirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=2.0.0->pykeen) (1.3.8)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->pykeen) (1.16.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna>=2.0.0->pykeen) (3.1.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->pykeen) (1.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->pykeen) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->pykeen) (1.3.0)\nDownloading pykeen-1.11.0-py3-none-any.whl (718 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.4/718.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading class_resolver-0.5.4-py3-none-any.whl (29 kB)\nDownloading pystow-0.6.1-py3-none-any.whl (38 kB)\nDownloading torch_max_mem-0.1.3-py3-none-any.whl (10 kB)\nDownloading torch_ppr-0.0.8-py3-none-any.whl (12 kB)\nDownloading click_default_group-1.2.4-py2.py3-none-any.whl (4.1 kB)\nDownloading docdata-0.0.4-py3-none-any.whl (9.1 kB)\nDownloading more_click-0.1.2-py3-none-any.whl (6.7 kB)\nInstalling collected packages: more-click, docdata, click-default-group, class-resolver, pystow, torch-max-mem, torch-ppr, pykeen\nSuccessfully installed class-resolver-0.5.4 click-default-group-1.2.4 docdata-0.0.4 more-click-0.1.2 pykeen-1.11.0 pystow-0.6.1 torch-max-mem-0.1.3 torch-ppr-0.0.8\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import networkx as nx\n\nG = nx.Graph()\n\n# Add nodes and edges based on the data\nfor index, row in train_df.iterrows():\n    trans_id = f'trans_{index}'\n    G.add_node(trans_id, label='transaction')\n    G.add_node(row['merchant'], label='merchant')\n    G.add_node(row['category'], label='category')\n    G.add_node(row['city'], label='city')\n    G.add_node(row['state'], label='state')\n    G.add_edge(trans_id, row['merchant'], relationship='made_at')\n    G.add_edge(trans_id, row['category'], relationship='belongs_to')\n    G.add_edge(trans_id, row['city'], relationship='located_in')\n    G.add_edge(trans_id, row['state'], relationship='in')\n    G.add_node(row['time_of_day_category'] , label='time')\n    G.add_edge(trans_id, row['time_of_day_category'] , relationship='time')\n    #G.add_node(row['cc_num'], label='cc_num')\n    #G.add_edge(trans_id, row['cc_num'], relationship='card')\n    G.add_node(row['job'], label='job')\n    G.add_edge(trans_id, row['job'], relationship='job')","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:04:50.353520Z","iopub.execute_input":"2025-01-14T16:04:50.353757Z","iopub.status.idle":"2025-01-14T16:05:50.625462Z","shell.execute_reply.started":"2025-01-14T16:04:50.353735Z","shell.execute_reply":"2025-01-14T16:05:50.624738Z"},"id":"690677af","trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from pykeen.pipeline import pipeline\nfrom pykeen.triples import TriplesFactory\nfrom sklearn.model_selection import train_test_split\nimport torch\n# Create triples for KG (subject, predicate, object)\ntriples = []\nfor index, row in train_df.iterrows():\n    trans_id = f'trans_{index}'\n    triples.append((trans_id, 'made_at', row['merchant']))\n    triples.append((trans_id, 'belongs_to', row['category']))\n    triples.append((trans_id, 'located_in', row['city']))\n    triples.append((trans_id, 'in', row['state']))\n    triples.append((trans_id, 'in', row['time_of_day_category']))\n    triples.append((trans_id, 'job', row['job']))\n    #triples.append((trans_id, 'card', row['cc_num']))\ntriples = np.array(triples)\n# Create a PyKEEN dataset\nfor i in range(25):\n    print(triples[i])\n\n# Check data types of the triples\nprint(type(triples[0][0]), type(triples[0][1]), type(triples[0][2]))\n\n# Remove malformed entries\nvalid_triples = [triple for triple in triples if len(triple) == 3]\ntriples = np.array(valid_triples)\n\n# Split the triples into training and testing sets\ntrain_triples, test_triples = train_test_split(triples, test_size=0.2, random_state=42)\ntrain_triples=triples\n# Create TriplesFactory objects for training and testing sets\ntrain_tf = TriplesFactory.from_labeled_triples(train_triples)\ntest_tf = TriplesFactory.from_labeled_triples(test_triples)\n\n# Print TriplesFactory details for debugging\nprint(train_tf)\nprint(test_tf)\n\n# Train a KG embedding model with both training and testing triples factories\nresult = pipeline(\n    training=train_tf,\n    testing=test_tf,\n    model='TransE',\n    training_kwargs=dict(num_epochs=10),\n)\nall_entities = train_tf.entity_to_id\nembeddings = result.model.entity_representations[0](indices=torch.arange(train_tf.num_entities, device=result.model.device)).cpu().detach().numpy()\n\n# Create a DataFrame with embeddings\nembedding_df = pd.DataFrame(embeddings, index=all_entities.keys())\n\n# Merge embeddings with labels\ntrain_df['embedding'] = train_df.index.map(lambda x: embedding_df.loc[f'trans_{x}'].values)","metadata":{"execution":{"iopub.status.busy":"2025-01-14T16:05:50.626320Z","iopub.execute_input":"2025-01-14T16:05:50.626768Z","execution_failed":"2025-01-14T17:16:53.520Z"},"id":"64dbbeac","outputId":"0fafdbf7-a4eb-430b-b998-b7176900433c","trusted":true},"outputs":[{"name":"stdout","text":"['trans_94102' 'made_at' 'fraud_Funk Group']\n['trans_94102' 'belongs_to' 'grocery_net']\n['trans_94102' 'located_in' 'Wilton']\n['trans_94102' 'in' 'ND']\n['trans_94102' 'in' 'Morning']\n['trans_94102' 'job' 'Designer, ceramics/pottery']\n['trans_198791' 'made_at' 'fraud_Prosacco, Kreiger and Kovacek']\n['trans_198791' 'belongs_to' 'home']\n['trans_198791' 'located_in' 'Colton']\n['trans_198791' 'in' 'WA']\n['trans_198791' 'in' 'Evening']\n['trans_198791' 'job' 'Chief Marketing Officer']\n['trans_1238587' 'made_at' 'fraud_Langworth, Boehm and Gulgowski']\n['trans_1238587' 'belongs_to' 'shopping_net']\n['trans_1238587' 'located_in' 'Brandon']\n['trans_1238587' 'in' 'FL']\n['trans_1238587' 'in' 'Evening']\n['trans_1238587' 'job' 'Environmental consultant']\n['trans_619078' 'made_at' 'fraud_Conroy-Emard']\n['trans_619078' 'belongs_to' 'food_dining']\n['trans_619078' 'located_in' 'Alpharetta']\n['trans_619078' 'in' 'GA']\n['trans_619078' 'in' 'Afternoon']\n['trans_619078' 'job' 'Prison officer']\n['trans_573850' 'made_at' 'fraud_Adams-Barrows']\n<class 'numpy.str_'> <class 'numpy.str_'> <class 'numpy.str_'>\nTriplesFactory(num_entities=650488, num_relations=5, create_inverse_triples=False, num_triples=3890028)\nTriplesFactory(num_entities=480379, num_relations=5, create_inverse_triples=False, num_triples=778006)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training epochs on cuda:0:   0%|          | 0/10 [00:00<?, ?epoch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06c9bbef195c4ab0a519f7998f879e5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batches on cuda:0:   0%|          | 0/15196 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating on cuda:0:   0%|          | 0.00/778k [00:00<?, ?triple/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef1d98229e94e858e15b7609ba3b9ca"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"train_df.to_csv(\"train_df_new.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-01-14T15:13:17.733512Z","iopub.status.idle":"2025-01-14T15:13:17.733755Z","shell.execute_reply":"2025-01-14T15:13:17.733656Z"},"trusted":true,"id":"Keb36WSiRPRH"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#train_df['embedding']=pd.read_csv(\"train_df_new_W_EMBEDDINGS.csv\")['embedding']\ntrain_df['embedding']=pd.read_csv(\"/kaggle/input/train-df-jan13-embeddings/train_df_new_13Jan2024.csv\")['embedding']","metadata":{"id":"S90gKAw5X7w5","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T12:57:43.142208Z","iopub.execute_input":"2025-01-14T12:57:43.142757Z","iopub.status.idle":"2025-01-14T12:57:56.648832Z","shell.execute_reply.started":"2025-01-14T12:57:43.142724Z","shell.execute_reply":"2025-01-14T12:57:56.647847Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"!pip install python-louvain\n\nfrom community import community_louvain\n\n# Calculate the Louvain community structure\npartition = community_louvain.best_partition(G)\n\n# Add the community assignments to the dataframe\ntrain_df['community'] = train_df.index.map(lambda x: partition.get(f'trans_{x}', -1))\n\n# Print or further analyze the community assignments\nprint(train_df[['community']])","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:14.456564Z","iopub.execute_input":"2025-01-14T17:25:14.456832Z","iopub.status.idle":"2025-01-14T17:25:18.977633Z","shell.execute_reply.started":"2025-01-14T17:25:14.456813Z","shell.execute_reply":"2025-01-14T17:25:18.974902Z"},"id":"qP39Fq-HEjec","trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: python-louvain in /usr/local/lib/python3.10/dist-packages (0.16)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from python-louvain) (3.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from python-louvain) (1.26.4)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-46c91b1e7a20>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calculate the Louvain community structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunity_louvain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Add the community assignments to the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"],"ename":"NameError","evalue":"name 'G' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.978133Z","iopub.status.idle":"2025-01-14T17:25:18.978392Z","shell.execute_reply":"2025-01-14T17:25:18.978269Z"},"id":"cDWi7p36CbN5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.dropna()","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.979123Z","iopub.status.idle":"2025-01-14T17:25:18.979486Z","shell.execute_reply":"2025-01-14T17:25:18.979324Z"},"id":"s18wN9iHJSuE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in train_df.columns:\n    if train_df[col].dtype == 'object' and col != 'embedding':  # Skip 'embedding' column\n        train_df[col] = train_df[col].astype('category')","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.980155Z","iopub.status.idle":"2025-01-14T17:25:18.980455Z","shell.execute_reply":"2025-01-14T17:25:18.980349Z"},"id":"JN2GGx-FJIR8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df=train_df.dropna()","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.981711Z","iopub.status.idle":"2025-01-14T17:25:18.981986Z","shell.execute_reply":"2025-01-14T17:25:18.981856Z"},"id":"cS6vgVtT08a1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_features = ['gender', 'community', 'time_of_day_category', 'job']\nfor col in categorical_features:\n    train_df[col] = train_df[col].astype('category')","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.982825Z","iopub.status.idle":"2025-01-14T17:25:18.983061Z","shell.execute_reply":"2025-01-14T17:25:18.982964Z"},"trusted":true,"id":"JeXDxlSmRPQ6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.983611Z","iopub.status.idle":"2025-01-14T17:25:18.983836Z","shell.execute_reply":"2025-01-14T17:25:18.983744Z"},"id":"t1U8SPQaez-d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.to_csv(\"train_df_new.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.984697Z","iopub.status.idle":"2025-01-14T17:25:18.984998Z","shell.execute_reply":"2025-01-14T17:25:18.984893Z"},"trusted":true,"id":"Keb36WSiRPRH"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\n# Fit and transform the 'gender' column in both training and validation data\ntrain_df['gender_encoded'] = le.fit_transform(train_df['gender'])\n\n\nX =  train_df[['amt', 'distance', 'age', 'gender_encoded','community','time_of_day_category','job']]#'predicted_labels'\ny = train_df['is_fraud']\n\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.985717Z","iopub.status.idle":"2025-01-14T17:25:18.985976Z","shell.execute_reply":"2025-01-14T17:25:18.985874Z"},"id":"a84a5a8f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\n\n# One-hot encode categorical features\nX_encoded = pd.get_dummies(X, columns=[ 'time_of_day_category', 'job'])\nfeatures = ['gender_encoded', 'community']\nfor col in features:\n    X_encoded[col] = X_encoded[col].astype('int')\n# Split the data\nX_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n\n# Initialize SMOTE\nsmote = SMOTE(random_state=42)\n\n# Apply SMOTE to the training data\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\n# Initialize the XGBoost model\nmodel = xgb.XGBClassifier(random_state=42)\n\n# Perform cross-validation\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(model, X_train_balanced, y_train_balanced, cv=cv, scoring='f1')\n\nprint(f\"Cross-Validation F1 Scores: {scores}\")\nprint(f\"Mean F1 Score: {scores.mean()}\")\n\n# Train the model on the balanced training data\nmodel.fit(X_train_balanced, y_train_balanced)\n\n# Predict on the validation set\ny_val_pred = model.predict(X_val)\n\n# Evaluate the model\nprint(f\"Classification Report:\\n{classification_report(y_val, y_val_pred)}\")\nprint(f\"Confusion Matrix:\\n{confusion_matrix(y_val, y_val_pred)}\")\n\n# Plot feature importance\nxgb.plot_importance(model)\nplt.title('Feature Importance')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.986682Z","iopub.status.idle":"2025-01-14T17:25:18.987005Z","shell.execute_reply":"2025-01-14T17:25:18.986852Z"},"id":"d5e5415e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# One-hot encode categorical features\nX_encoded = pd.get_dummies(X, columns=['time_of_day_category', 'job'])\nfeatures = ['gender_encoded', 'community']\nfor col in features:\n    X_encoded[col] = X_encoded[col].astype('int')\n\n# Split the data\nX_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n\n# Initialize the XGBoost model\nmodel = xgb.XGBClassifier(random_state=42,enable_categorical=True)\n\n# Perform cross-validation\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n\nprint(f\"Cross-Validation F1 Scores: {scores}\")\nprint(f\"Mean F1 Score: {scores.mean()}\")\n\n# Train the model on the training data\nmodel.fit(X_train, y_train)\n\n# Predict on the validation set\ny_val_pred = model.predict(X_val)\n\n# Evaluate the model\nprint(f\"Classification Report:\\n{classification_report(y_val, y_val_pred)}\")\nprint(f\"Confusion Matrix:\\n{confusion_matrix(y_val, y_val_pred)}\")\n\n# Plot feature importance\nxgb.plot_importance(model)\nplt.title('Feature Importance')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.987792Z","iopub.status.idle":"2025-01-14T17:25:18.988153Z","shell.execute_reply":"2025-01-14T17:25:18.987997Z"},"trusted":true,"id":"mUFf4t1VRPRJ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score, f1_score\n\ny_val_pred_proba = model.predict_proba(X_val)[:, 1]\ncutoffs = np.linspace(0, 1, 101)\nprecision = []\nrecall = []\nf1 = []\n\nfor cutoff in cutoffs:\n    y_val_pred = (y_val_pred_proba >= cutoff).astype(int)\n    precision.append(precision_score(y_val, y_val_pred))\n    recall.append(recall_score(y_val, y_val_pred))\n    f1.append(f1_score(y_val, y_val_pred))\n\nplt.figure(figsize=(10, 6))\nplt.plot(cutoffs, precision, label='Precision')\nplt.plot(cutoffs, recall, label='Recall')\nplt.plot(cutoffs, f1, label='F1 Score')\nplt.xlabel('Cutoff Probability')\nplt.ylabel('Score')\nplt.title('Precision, Recall, and F1 Score vs. Cutoff Probability')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\nbest_cutoff = cutoffs[np.argmax(f1)]\nprint(f\"Best cutoff for F1 Score: {best_cutoff}\")\n\ny_val_pred = (y_val_pred_proba >= best_cutoff).astype(int)\nprint(classification_report(y_val,y_val_pred))\n\n\nxgb.plot_importance(model)\nplt.title('Feature Importance')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.988892Z","iopub.status.idle":"2025-01-14T17:25:18.989251Z","shell.execute_reply":"2025-01-14T17:25:18.989094Z"},"id":"Jl3J-a1i0S23","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/fraud-detection/fraudTest.csv')","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.990180Z","iopub.status.idle":"2025-01-14T17:25:18.990586Z","shell.execute_reply":"2025-01-14T17:25:18.990425Z"},"id":"Cxnd-V4El7x2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.columns","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.991241Z","iopub.status.idle":"2025-01-14T17:25:18.991646Z","shell.execute_reply":"2025-01-14T17:25:18.991467Z"},"trusted":true,"id":"tswg-1w8RPRL"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TransE_model=result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:25:18.992358Z","iopub.status.idle":"2025-01-14T17:25:18.992720Z","shell.execute_reply":"2025-01-14T17:25:18.992561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import networkx as nx\nfrom community import community_louvain\ntest_df['trans_date_trans_time'] = pd.to_datetime(test_df['trans_date_trans_time'])\ntest_df['time_of_day'] = (test_df['trans_date_trans_time'].dt.hour * 60) + test_df['trans_date_trans_time'].dt.minute\ntest_df['time_of_day_category'] = pd.cut(test_df['time_of_day'], bins=[0, 6*60, 12*60, 18*60, 24*60], labels=['Night', 'Morning', 'Afternoon', 'Evening'], right=False)\ntest_df['unix_time_c'] = pd.to_datetime(test_df['unix_time'], unit='s')\ntest_df['time_of_day_uc'] = (test_df['unix_time_c'].dt.hour * 60) + test_df['unix_time_c'].dt.minute\ntest_df['time_of_day_category_uc'] = pd.cut(test_df['time_of_day_uc'], bins=[0, 6*60, 12*60, 18*60, 24*60], labels=['Night', 'Morning', 'Afternoon', 'Evening'], right=False)\n\ntest_df = test_df.drop(['Unnamed: 0', 'trans_date_trans_time','trans_num', 'unix_time'],axis=1)\ntest_df['distance']= (test_df['lat'] - test_df['merch_lat'])**2 + (test_df['long'] - test_df['merch_long'])**2\n#test_df['merchant'] = test_df['merchant'].apply(clean_text)\n#test_df['category'] = test_df['category'].apply(clean_text)\ntest_df['city_state'] = test_df['city'] + '_' + test_df['state']\ntest_df = test_df.dropna(subset=['dob'])\ntest_df['age'] = test_df['dob'].apply(calculate_age)\n\ncategorical_cols = ['category', 'gender', 'job','city','state','merchant','street','city_state']\nfor col in categorical_cols:\n    test_df[col] = test_df[col].astype('category')\n\ntest_df.drop(['merch_lat', 'merch_long','lat', 'long','street','zip','city_pop','dob'],axis=1,inplace=True)\n\n\n# Create graph for test data\nG_test = nx.Graph()\nfor index, row in test_df.iterrows():\n    trans_id = f'trans_{index}'\n    G_test.add_node(trans_id, label='transaction')\n    G_test.add_node(row['merchant'], label='merchant')\n    G_test.add_node(row['category'], label='category')\n    G_test.add_node(row['city'], label='city')\n    G_test.add_node(row['state'], label='state')\n    G_test.add_edge(trans_id, row['merchant'], relationship='made_at')\n    G_test.add_edge(trans_id, row['category'], relationship='belongs_to')\n    G_test.add_edge(trans_id, row['city'], relationship='located_in')\n    G_test.add_edge(trans_id, row['state'], relationship='in')\n    G_test.add_node(row['time_of_day_category'], label='time')\n    G_test.add_edge(trans_id, row['time_of_day_category'], relationship='time')\n    #G_test.add_node(row['cc_num'], label='cc_num')\n    #G_test.add_edge(trans_id, row['cc_num'], relationship='card')\n    G_test.add_node(row['job'], label='job')\n    G_test.add_edge(trans_id, row['job'], relationship='job')\n# Community detection for test data\npartition_test = community_louvain.best_partition(G_test)\ntest_df['community'] = test_df.index.map(lambda x: partition_test.get(f'trans_{x}', -1))\n\n# Label Propagation for test data (using the trained model)\ntransaction_nodes_test = [node for node in G_test.nodes() if str(node).startswith('trans_')]\n#graph_laplacian_test = nx.laplacian_matrix(G_test, nodelist=transaction_nodes_test).toarray()\n#predicted_labels_test = label_prop_model.predict(graph_laplacian_test) # Use the trained model here\n#test_df['predicted_labels'] = predicted_labels_test\n","metadata":{"id":"tnOYFgtPRPRM","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:25:18.993646Z","iopub.status.idle":"2025-01-14T17:25:18.993999Z","shell.execute_reply":"2025-01-14T17:25:18.993845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pykeen.triples.utils import get_entities\nentity_to_id = TransE_model.training.entity_to_id\n\n# Create triples for the test data\ntest_triples = []\nfor index, row in test_df.iterrows():\n    trans_id = f'trans_{index}'\n    test_triples.append((trans_id, 'made_at', row['merchant']))\n    test_triples.append((trans_id, 'belongs_to', row['category']))\n    test_triples.append((trans_id, 'located_in', row['city']))\n    test_triples.append((trans_id, 'in', row['state']))\n    test_triples.append((trans_id, 'in', row['time_of_day_category']))\n    test_triples.append((trans_id, 'job', row['job']))\n    #test_triples.append((trans_id, 'card', row['cc_num']))\ntest_triples = np.array(test_triples)\n\n# Remove malformed entries (if any)\nvalid_test_triples = [triple for triple in test_triples if len(triple) == 3 and all(isinstance(item, str) for item in triple)]\ntest_triples = np.array(valid_test_triples)\n\n\n# Create a TriplesFactory for the test data, handling unknown entities\ntest_tf = TriplesFactory.from_labeled_triples(\n    triples=test_triples,\n    entity_to_id=entity_to_id,  # Use the entity to ID mapping from training\n    relation_to_id=TransE_model.training.relation_to_id,  # Use relation mapping from training\n    create_inverse_triples=False, # Assuming you don't need inverse triples\n)\n\n","metadata":{"id":"EfZpyN2dVdH6","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:25:18.995121Z","iopub.status.idle":"2025-01-14T17:25:18.995506Z","shell.execute_reply":"2025-01-14T17:25:18.995344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Get entity embeddings for the test data\n# Get all entity IDs present in the test data\nall_test_entity_ids = set(test_tf.entities_to_ids(get_entities(test_tf.mapped_triples))) # Instead of test_tf.get_entities()\n\n# Filter entity embeddings for entities present in test data\ntest_entity_indices = torch.tensor([test_tf.entity_to_id[entity] for entity in test_tf.entity_to_id if test_tf.entity_to_id[entity] in all_test_entity_ids], device=TransE_model.model.device)\ntest_embeddings = TransE_model.model.entity_representations[0](indices=test_entity_indices).cpu().detach().numpy()\n\n# Create a DataFrame with embeddings for the test data, using filtered entity IDs\ntest_embedding_df = pd.DataFrame(test_embeddings, index=test_entity_indices.cpu().numpy())\n\n# Merge embeddings with the test DataFrame, using numeric entity IDs\ntest_df['embedding'] = test_df.index.map(lambda x: test_embedding_df.loc[test_tf.entity_to_id.get(f'trans_{x}')].values if test_tf.entity_to_id.get(f'trans_{x}') is not None else None)","metadata":{"id":"IiVu0aagboVa","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:25:18.996256Z","iopub.status.idle":"2025-01-14T17:25:18.996637Z","shell.execute_reply":"2025-01-14T17:25:18.996477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['gender_encoded'] = le.transform(test_df['gender'])","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.997306Z","iopub.status.idle":"2025-01-14T17:25:18.997667Z","shell.execute_reply":"2025-01-14T17:25:18.997507Z"},"trusted":true,"id":"eeDBfzMpRPRN"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.to_csv(\"test_df_new.csv\")","metadata":{"id":"V_wYGQAMWRf_","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:25:18.998352Z","iopub.status.idle":"2025-01-14T17:25:18.998708Z","shell.execute_reply":"2025-01-14T17:25:18.998549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df_trim=test_df[['amt', 'distance', 'age', 'gender_encoded', 'community', 'time_of_day_category', 'job']]\ntest_df_encoded = pd.get_dummies(test_df_trim, columns=['time_of_day_category', 'job'])\nfor col in features:\n    test_df_encoded[col] = test_df_encoded[col].astype('int')\n\nmissing_cols = set(X_train.columns) - set(test_df_encoded.columns)\nfor col in missing_cols:\n    test_df_encoded[col] = 0\n\ntest_df_encoded = test_df_encoded[X_train.columns]\n\n\nX_test = test_df_encoded\ny_test_pred_proba = model.predict_proba(X_test)[:, 1]\ny_test_pred = (y_test_pred_proba >= best_cutoff).astype(int) # Use the best cutoff from training\n\n# Evaluate the model on the test data\nprint(classification_report(test_df['is_fraud'], y_test_pred)) # Assuming 'is_fraud' column exists in test_df\nprint(confusion_matrix(test_df['is_fraud'], y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:18.999353Z","iopub.status.idle":"2025-01-14T17:25:18.999723Z","shell.execute_reply":"2025-01-14T17:25:18.999561Z"},"trusted":true,"id":"M8AaDNSjRPRN"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### Use stacking","metadata":{"id":"ca42c0c5"}},{"cell_type":"code","source":"!pip install scikit-learn==1.2.2\n!pip install xgboost==1.7.5\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n\n\nbase_learners = [\n    ('rf',RandomForestClassifier(n_estimators=100)),\n    ('xgb', xgb.XGBClassifier(random_state=42, enable_categorical=True))\n]\n\nmeta_learner = LogisticRegression()\nstacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner)\n\nstacking_model.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:19.000862Z","iopub.status.idle":"2025-01-14T17:25:19.001145Z","shell.execute_reply":"2025-01-14T17:25:19.001044Z"},"id":"7a6cb7cd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model = xgb.XGBClassifier(early_stopping_rounds=10, eval_metric='auc',enable_categorical=True)\n#model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)\n\n# Make predictions on the validation set\ny_val_pred = stacking_model.predict(X_val)\n\nprint(f\"classification report \\n {classification_report(y_val, y_val_pred)}\")\nprint(f\"confusion_matrix \\n {confusion_matrix(y_val, y_val_pred)}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:19.001697Z","iopub.status.idle":"2025-01-14T17:25:19.001922Z","shell.execute_reply":"2025-01-14T17:25:19.001830Z"},"id":"97d74d6a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = stacking_model.predict(X_test)\ny_test=test_df['is_fraud']\nprint(f\"classification report \\n {classification_report(y_test, y_pred)}\")\nprint(f\"confusion_matrix \\n {confusion_matrix(y_test, y_pred)}\")","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:19.002766Z","iopub.status.idle":"2025-01-14T17:25:19.003095Z","shell.execute_reply":"2025-01-14T17:25:19.002961Z"},"trusted":true,"id":"A65_i13SRPRQ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install LIME\n!pip install lime\n\nimport lime\nimport lime.lime_tabular\nimport numpy as np\n\n# Assuming you have a trained stacking classifier named 'stacking_clf'\n# and your training data is in 'X_train' and 'y_train'\n\n# Create a LIME explainer\nexplainer = lime.lime_tabular.LimeTabularExplainer(\n    training_data=np.array(X_train),\n    feature_names=X_train.columns,\n    class_names=['Not Fraud', 'Fraud'],\n    mode='classification'\n)\n\n# Select an instance to explain\ninstance_idx = 0  # Change this to the index of the instance you want to explain\ninstance = X_train.iloc[instance_idx]\n\n# Generate explanation\nexp = explainer.explain_instance(\n    data_row=instance,\n    predict_fn=stacking_model.predict_proba\n)\n\n# Display explanation\nexp.show_in_notebook(show_table=True, show_all=False)","metadata":{"id":"DMmsRB4wRPRR","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:25:19.003753Z","iopub.status.idle":"2025-01-14T17:25:19.003979Z","shell.execute_reply":"2025-01-14T17:25:19.003886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n\nmodel = xgb.XGBClassifier(early_stopping_rounds =5 ,eval_metric='auc', random_state=42,enable_categorical=True,scale_pos_weight=scale_pos_weight)\nmodel.fit(X_train, y_train,eval_set=[(X_val, y_val)])\n\ny_val_pred = model.predict(X_val)\n\n\nprint(f\"classification report \\n {classification_report(y_val, y_val_pred)}\")\nprint(f\"confusion_matrix \\n {confusion_matrix(y_val, y_val_pred)}\")\n\nxgb.plot_importance(model)\nplt.title('Feature Importance')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:19.004733Z","iopub.status.idle":"2025-01-14T17:25:19.005059Z","shell.execute_reply":"2025-01-14T17:25:19.004906Z"},"id":"bfb622d6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{"id":"w7RpZw6eRPRS"}},{"cell_type":"code","source":"\ndf_majority = train_df[train_df.is_fraud==0]\ndf_minority = train_df[train_df.is_fraud==1]\n\n# Upsample minority class\nfrom sklearn.utils import resample\ndf_minority_upsampled = resample(df_minority,\n                                 replace=True,     # sample with replacement\n                                 n_samples=int(0.05*len(train_df)),    # to match majority class\n                                 random_state=123) # reproducible results\n\n# Combine majority class with upsampled minority class\ntrain_df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n\n# Display new class counts\ntrain_df_upsampled.is_fraud.value_counts()\n\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:19.005872Z","iopub.status.idle":"2025-01-14T17:25:19.006180Z","shell.execute_reply":"2025-01-14T17:25:19.006026Z"},"id":"7504f99c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nle = LabelEncoder()\ntrain_df_upsampled['gender_encoded'] = le.fit_transform(train_df_upsampled['gender'])\n\nX =  train_df_upsampled[['amt', 'distance', 'age', 'gender_encoded','community','time_of_day_category','job']]\ny = train_df_upsampled['is_fraud']\nX_encoded = pd.get_dummies(X, columns=['time_of_day_category', 'job'])\nX_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n\n# Initialize and train the XGBoost model\nmodel = xgb.XGBClassifier(random_state=42, enable_categorical=True)\nmodel.fit(X_train, y_train)\ny_val_pred = model.predict(X_val)\n\nprint(f\"classification report \\n {classification_report(y_val, y_val_pred)}\")\nprint(f\"confusion_matrix \\n {confusion_matrix(y_val, y_val_pred)}\")\n\nxgb.plot_importance(model)\nplt.title('Feature Importance')\nplt.show()\n\ny_val_pred_proba = model.predict_proba(X_val)[:, 1]\ncutoffs = np.linspace(0, 1, 101)\nprecision = []\nrecall = []\nf1 = []\n\nfor cutoff in cutoffs:\n    y_val_pred = (y_val_pred_proba >= cutoff).astype(int)\n    precision.append(precision_score(y_val, y_val_pred))\n    recall.append(recall_score(y_val, y_val_pred))\n    f1.append(f1_score(y_val, y_val_pred))\n\nplt.figure(figsize=(10, 6))\nplt.plot(cutoffs, precision, label='Precision')\nplt.plot(cutoffs, recall, label='Recall')\nplt.plot(cutoffs, f1, label='F1 Score')\nplt.xlabel('Cutoff Probability')\nplt.ylabel('Score')\nplt.title('Precision, Recall, and F1 Score vs. Cutoff Probability')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nbest_cutoff = cutoffs[np.argmax(f1)]\nprint(f\"Best cutoff for F1 Score: {best_cutoff}\")\n\ny_val_pred = (y_val_pred_proba >= best_cutoff).astype(int)\nprint(classification_report(y_val,y_val_pred))\n\nxgb.plot_importance(model)\nplt.title('Feature Importance')\nplt.show()\n\nprint(\"Testing\\n\")\ntest_df_trim=test_df[['amt', 'distance', 'age', 'gender_encoded', 'community', 'time_of_day_category', 'job']]\ntest_df_encoded = pd.get_dummies(test_df_trim, columns=['time_of_day_category', 'job'])\n\nmissing_cols = set(X_train.columns) - set(test_df_encoded.columns)\nfor col in missing_cols:\n    test_df_encoded[col] = 0\n\ntest_df_encoded = test_df_encoded[X_train.columns]\n\n\nX_test = test_df_encoded\ny_test_pred_proba = model.predict_proba(X_test)[:, 1]\ny_test_pred = (y_test_pred_proba >= best_cutoff).astype(int) # Use the best cutoff from training\n\n# Evaluate the model on the test data\nprint(classification_report(test_df['is_fraud'], y_test_pred)) # Assuming 'is_fraud' column exists in test_df\nprint(confusion_matrix(test_df['is_fraud'], y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2025-01-14T17:25:19.007019Z","iopub.status.idle":"2025-01-14T17:25:19.007325Z","shell.execute_reply":"2025-01-14T17:25:19.007190Z"},"id":"hPOnZGYY1h0i","trusted":true},"outputs":[],"execution_count":null}]}